{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c345a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD, Adam\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81894a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>BO1016_pressure</th>\n",
       "      <th>BO1017_pressure</th>\n",
       "      <th>BO1029_pressure</th>\n",
       "      <th>NB1017_pressure</th>\n",
       "      <th>WS8007_pressure</th>\n",
       "      <th>NMN BOO Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-03 00:00:00</td>\n",
       "      <td>21.488</td>\n",
       "      <td>20.313</td>\n",
       "      <td>13.168</td>\n",
       "      <td>20.039</td>\n",
       "      <td>12.678</td>\n",
       "      <td>21.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-03 00:15:00</td>\n",
       "      <td>21.864</td>\n",
       "      <td>20.885</td>\n",
       "      <td>13.504</td>\n",
       "      <td>20.619</td>\n",
       "      <td>12.709</td>\n",
       "      <td>21.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-03 00:30:00</td>\n",
       "      <td>22.005</td>\n",
       "      <td>20.924</td>\n",
       "      <td>13.285</td>\n",
       "      <td>20.713</td>\n",
       "      <td>12.709</td>\n",
       "      <td>20.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-03 00:45:00</td>\n",
       "      <td>22.153</td>\n",
       "      <td>21.214</td>\n",
       "      <td>13.379</td>\n",
       "      <td>20.995</td>\n",
       "      <td>12.709</td>\n",
       "      <td>21.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-03 01:00:00</td>\n",
       "      <td>22.373</td>\n",
       "      <td>21.386</td>\n",
       "      <td>13.191</td>\n",
       "      <td>21.190</td>\n",
       "      <td>12.709</td>\n",
       "      <td>20.787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time  BO1016_pressure  BO1017_pressure  BO1029_pressure  \\\n",
       "0 2023-09-03 00:00:00           21.488           20.313           13.168   \n",
       "1 2023-09-03 00:15:00           21.864           20.885           13.504   \n",
       "2 2023-09-03 00:30:00           22.005           20.924           13.285   \n",
       "3 2023-09-03 00:45:00           22.153           21.214           13.379   \n",
       "4 2023-09-03 01:00:00           22.373           21.386           13.191   \n",
       "\n",
       "   NB1017_pressure  WS8007_pressure  NMN BOO Pressure  \n",
       "0           20.039           12.678            21.444  \n",
       "1           20.619           12.709            21.264  \n",
       "2           20.713           12.709            20.787  \n",
       "3           20.995           12.709            21.076  \n",
       "4           21.190           12.709            20.787  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data_for_multivariate_LSTM.csv\", parse_dates=[\"Time\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f52a51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-03 00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-03 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-03 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-03 00:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time\n",
       "0 2023-09-03 00:00:00\n",
       "1 2023-09-03 00:05:00\n",
       "2 2023-09-03 00:10:00\n",
       "3 2023-09-03 00:15:00\n",
       "4 2023-09-03 00:20:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_index = pd.date_range(start = df[\"Time\"].min(), end = df[\"Time\"].max(), freq = \"5T\" )\n",
    "new_df = pd.DataFrame(new_index, columns=['Time'])\n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a45b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'BO1016_pressure', 'BO1017_pressure', 'BO1029_pressure',\n",
      "       'NB1017_pressure', 'WS8007_pressure', 'NMN BOO Pressure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Kết hợp DataFrame mới với DataFrame gốc\n",
    "merged_df = pd.merge(new_df, df, how='left', on=\"Time\")\n",
    "feature = merged_df.drop(\"Time\", axis = 1).columns\n",
    "# Nội suy tuyến tính trên các khoảng thời gian cụ thể\n",
    "merged_df[feature] = merged_df[feature].interpolate(method='linear')\n",
    "# merged_df[feature] = merged_df[feature].interpolate(method='linear interp')\n",
    "merged_df.to_csv(\"Data_for_multivariate_LSTM_5T.csv\")\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b118f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     BO1016_pressure  BO1017_pressure  BO1029_pressure  \\\n",
      "Time                                                                     \n",
      "2023-09-03 00:00:00         0.578953         0.629499         0.195371   \n",
      "2023-09-03 00:05:00         0.582469         0.635414         0.198729   \n",
      "2023-09-03 00:10:00         0.585984         0.641330         0.202087   \n",
      "2023-09-03 00:15:00         0.589499         0.647245         0.205445   \n",
      "2023-09-03 00:20:00         0.590817         0.647648         0.203256   \n",
      "\n",
      "                     NB1017_pressure  WS8007_pressure  NMN BOO Pressure  \n",
      "Time                                                                     \n",
      "2023-09-03 00:00:00         0.610759         0.233757          0.203199  \n",
      "2023-09-03 00:05:00         0.616939         0.241474          0.201544  \n",
      "2023-09-03 00:10:00         0.623119         0.249191          0.199890  \n",
      "2023-09-03 00:15:00         0.629299         0.256908          0.198235  \n",
      "2023-09-03 00:20:00         0.630301         0.256908          0.193851  \n"
     ]
    }
   ],
   "source": [
    "merged_df.set_index(\"Time\", inplace=True) #set index\n",
    "\n",
    "state_ = merged_df\n",
    "features = state_.columns\n",
    "scaler =MMS() #scale data\n",
    "state = scaler.fit_transform(state_[features])\n",
    "state = pd.DataFrame(columns=features, data=state, index = merged_df.index)\n",
    "print(state.head())\n",
    "\n",
    "merged_df[\"NMN BOO Pressure\"] = scaler.fit_transform(merged_df[[\"NMN BOO Pressure\"]])\n",
    "control = merged_df[\"NMN BOO Pressure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6ebf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21917, 5, 6), (21917,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Loop qua các hàng của dataframe để lấy các cửa sổ thời gian t-5 đến t và giá trị tại t+1 cho Y\n",
    "for i in range(5, len(df) - 1):\n",
    "    X.append(state.iloc[i-5:i].values)  # Lấy cửa sổ thời gian t-5 đến < t\n",
    "    Y.append(control.iloc[i])  # Lấy giá trị t của cột cuối cùng\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X_state_tr, X_state_te, y_state_tr, y_state_te = train_test_split(X, Y, test_size = 0.25, random_state = 25)\n",
    "X_state_tr.shape , y_state_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d80adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m model1\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt1, loss\u001b[38;5;241m=\u001b[39mls)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Prepare decoder input data (initial zeros for the first prediction step)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m decoder_input_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mzeros((X_state_tr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m     35\u001b[0m apply1 \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mfit([X_state_tr, decoder_input_data], y_state_tr, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Define the optimizer\n",
    "opt1 = Adam(learning_rate=0.0005)\n",
    "ls = 'mae'\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(5, 6))\n",
    "encoder_lstm = LSTM(64, recurrent_activation='tanh', return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None, 6))\n",
    "decoder_lstm = LSTM(64, recurrent_activation='tanh', return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense_1 = Dense(32, activation='elu')\n",
    "decoder_outputs = decoder_dense_1(decoder_outputs)\n",
    "decoder_dropout_1 = Dropout(0.1)(decoder_outputs)\n",
    "decoder_dense_2 = Dense(16, activation='elu')\n",
    "decoder_outputs = decoder_dense_2(decoder_dropout_1)\n",
    "decoder_dense_3 = Dense(8, activation='elu')\n",
    "decoder_outputs = decoder_dense_3(decoder_outputs)\n",
    "decoder_dense_4 = Dense(1)\n",
    "decoder_outputs = decoder_dense_4(decoder_outputs)\n",
    "# Create the model\n",
    "model1 = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer=opt1, loss=ls)\n",
    "# Prepare decoder input data (initial zeros for the first prediction step)\n",
    "decoder_input_data = np.zeros((X_state_tr.shape[0], 1, 6))\n",
    "\n",
    "# Fit the model\n",
    "apply1 = model1.fit([X_state_tr, decoder_input_data], y_state_tr, batch_size=1024, epochs=200, validation_split=0.2)\n",
    "\n",
    "# Prepare decoder input data for testing\n",
    "decoder_input_test_data = np.zeros((X_state_te.shape[0], 1, 6))\n",
    "\n",
    "# Evaluate the model\n",
    "score1 = model1.evaluate([X_state_te, decoder_input_test_data], y_state_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc4217c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimof_input:  5\n",
      "1.0\n",
      "dimof_output:  2\n",
      "X training data shape =  (65547, 288, 5)\n",
      "Y training data shape (65547, 2)\n",
      "X test data shape =  (21849, 288, 5)\n",
      "Y test data shape (21849, 2)\n"
     ]
    }
   ],
   "source": [
    "# Etract data from dataframe and rescale \n",
    "from keras.utils import to_categorical\n",
    "BOO_df = merged_df\n",
    "Y = np.array(BOO_df['NMN BOO Pressure'].values)\n",
    "X = np.array(BOO_df[['BO1016_pressure' , 'BO1017_pressure' , 'BO1029_pressure' ,'NB1017_pressure' ,'WS8007_pressure']])\n",
    "\n",
    "# Get dimensions of input and output \n",
    "dimof_output = int(np.max(Y) + 1)\n",
    "dimof_input = X.shape[1]\n",
    "print('dimof_input: ', dimof_input)\n",
    "print(np.max(Y))\n",
    "print('dimof_output: ', dimof_output)\n",
    "\n",
    "# Scale/whiten the X data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Set y as categorical data\n",
    "Y = to_categorical(Y, dimof_output)\n",
    "# --------------------------------------------------\n",
    "def create_dataset(X, Y, **options):\n",
    "    \"\"\"Convert an array of X, Y values into a dataset matrix for and LSTM\"\"\"\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back - 1):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def train_test_split_sequential(X, Y, **options):\n",
    "    \"\"\"Splits data into train test sets, based on a fraction test_size samples\n",
    "    from the end of the timeseries\"\"\"\n",
    "    \n",
    "    test_size = options.pop('test_size', None)\n",
    "    if test_size is None:\n",
    "        test_size = 0.25\n",
    "        \n",
    "    n_sample = len(Y)\n",
    "    n_test = int(n_sample * test_size)\n",
    "        \n",
    "    X_train = X[:-n_test]\n",
    "    Y_train = Y[:-n_test]\n",
    "\n",
    "    X_test = X[-n_test:]\n",
    "    Y_test = Y[-n_test:]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Predictions will be based on look_back minutes of data:\n",
    "look_back = 12*24\n",
    "X_all, Y_all = create_dataset(X, Y, look_back=look_back)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split_sequential(X_all, Y_all, test_size=0.25)\n",
    "\n",
    "print('X training data shape = ', X_train.shape)\n",
    "print('Y training data shape', Y_train.shape)\n",
    "\n",
    "print('X test data shape = ', X_test.shape)\n",
    "print('Y test data shape', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ade99f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fe2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 2)                 64        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70 (280.00 Byte)\n",
      "Trainable params: 70 (280.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "2049/2049 [==============================] - 254s 107ms/step - loss: 0.0285 - val_loss: 7.3867e-06\n",
      "Epoch 2/32\n",
      "2049/2049 [==============================] - 167s 81ms/step - loss: 6.0570e-05 - val_loss: 8.4323e-07\n",
      "Epoch 3/32\n",
      "2049/2049 [==============================] - 178s 87ms/step - loss: 2.7758e-05 - val_loss: 4.3098e-07\n",
      "Epoch 4/32\n",
      "2049/2049 [==============================] - 169s 82ms/step - loss: 2.2892e-05 - val_loss: 2.8658e-07\n",
      "Epoch 5/32\n",
      "2049/2049 [==============================] - 183s 90ms/step - loss: 2.0546e-05 - val_loss: 2.1469e-07\n",
      "Epoch 6/32\n",
      "2049/2049 [==============================] - 186s 91ms/step - loss: 1.9490e-05 - val_loss: 1.7105e-07\n",
      "Epoch 7/32\n",
      "2049/2049 [==============================] - 185s 90ms/step - loss: 1.8737e-05 - val_loss: 1.4190e-07\n",
      "Epoch 8/32\n",
      "2049/2049 [==============================] - 187s 91ms/step - loss: 1.8194e-05 - val_loss: 1.2122e-07\n",
      "Epoch 9/32\n",
      "2049/2049 [==============================] - 182s 89ms/step - loss: 1.7832e-05 - val_loss: 1.0558e-07\n",
      "Epoch 10/32\n",
      "2049/2049 [==============================] - 161s 78ms/step - loss: 1.7488e-05 - val_loss: 9.3643e-08\n",
      "Epoch 11/32\n",
      "2049/2049 [==============================] - 166s 81ms/step - loss: 1.7292e-05 - val_loss: 8.3946e-08\n",
      "Epoch 12/32\n",
      "2049/2049 [==============================] - 187s 91ms/step - loss: 1.7083e-05 - val_loss: 7.6087e-08\n",
      "Epoch 13/32\n",
      "2049/2049 [==============================] - 203s 99ms/step - loss: 1.6922e-05 - val_loss: 6.9571e-08\n",
      "Epoch 14/32\n",
      "2049/2049 [==============================] - 194s 95ms/step - loss: 1.6796e-05 - val_loss: 6.4041e-08\n",
      "Epoch 15/32\n",
      "2049/2049 [==============================] - 190s 93ms/step - loss: 1.6702e-05 - val_loss: 5.9252e-08\n",
      "Epoch 16/32\n",
      "2049/2049 [==============================] - 178s 87ms/step - loss: 1.6505e-05 - val_loss: 5.5279e-08\n",
      "Epoch 17/32\n",
      "2049/2049 [==============================] - 171s 83ms/step - loss: 1.6462e-05 - val_loss: 5.1801e-08\n",
      "Epoch 18/32\n",
      "2049/2049 [==============================] - 160s 78ms/step - loss: 1.6428e-05 - val_loss: 4.8640e-08\n",
      "Epoch 19/32\n",
      "2049/2049 [==============================] - 251s 122ms/step - loss: 1.6365e-05 - val_loss: 4.5824e-08\n",
      "Epoch 20/32\n",
      "2049/2049 [==============================] - 342s 167ms/step - loss: 1.6301e-05 - val_loss: 4.3319e-08\n",
      "Epoch 21/32\n",
      "2049/2049 [==============================] - 358s 175ms/step - loss: 1.6182e-05 - val_loss: 4.1139e-08\n",
      "Epoch 22/32\n",
      "2049/2049 [==============================] - 312s 152ms/step - loss: 1.6186e-05 - val_loss: 3.9129e-08\n",
      "Epoch 23/32\n",
      "2049/2049 [==============================] - 272s 133ms/step - loss: 1.6159e-05 - val_loss: 3.7277e-08\n",
      "Epoch 24/32\n",
      "2049/2049 [==============================] - 169s 82ms/step - loss: 1.6120e-05 - val_loss: 3.5588e-08\n",
      "Epoch 25/32\n",
      "2049/2049 [==============================] - 176s 86ms/step - loss: 1.6062e-05 - val_loss: 3.4078e-08\n",
      "Epoch 26/32\n",
      "2049/2049 [==============================] - 170s 83ms/step - loss: 1.6047e-05 - val_loss: 3.2659e-08\n",
      "Epoch 27/32\n",
      "2049/2049 [==============================] - 174s 85ms/step - loss: 1.5999e-05 - val_loss: 3.1377e-08\n",
      "Epoch 28/32\n",
      "2049/2049 [==============================] - 166s 81ms/step - loss: 1.5976e-05 - val_loss: 3.0186e-08\n",
      "Epoch 29/32\n",
      "2049/2049 [==============================] - 194s 95ms/step - loss: 1.5963e-05 - val_loss: 2.9062e-08\n",
      "Epoch 30/32\n",
      "2049/2049 [==============================] - 181s 89ms/step - loss: 1.5889e-05 - val_loss: 2.8046e-08\n",
      "Epoch 31/32\n",
      "2049/2049 [==============================] - 203s 99ms/step - loss: 1.5899e-05 - val_loss: 2.7093e-08\n",
      "Epoch 32/32\n",
      "2049/2049 [==============================] - 168s 82ms/step - loss: 1.5840e-05 - val_loss: 2.6215e-08\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "batch_size = 32\n",
    "dropout = 0.4\n",
    "look_back = 12*24 # Based on your dataset creation\n",
    "dimof_input = 5  # Number of features\n",
    "dimof_output = 2  # Number of target values\n",
    "# Create the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=dimof_output, input_shape=(look_back, dimof_input)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(dimof_output, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "# -----------------------------------------------------------\n",
    "num_epoch = 32\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "# earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    epochs=num_epoch,  # corrected from nb_epoch to epochs\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4886dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelK_info.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"modelK.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"modelK_weights.h5\")\n",
    "\n",
    "# Lưu siêu tham số và các thông tin khác bằng joblib\n",
    "model_info = {\n",
    "    \"modelK_json_path\": \"modelK.json\",\n",
    "    \"modelK_weights_path\": \"modelK_weights.h5\",\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"rmsprop\",\n",
    "        \"learning_rate\": 0.001\n",
    "    },\n",
    "    \"loss\": 'mae'\n",
    "}\n",
    "\n",
    "joblib.dump(model_info, 'modelK_info.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
