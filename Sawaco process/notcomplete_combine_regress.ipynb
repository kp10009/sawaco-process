{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43ddf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD, Adam\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dad11227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_time             0\n",
      "BO1013_FLOW1          0\n",
      "BO1016_Pressure(m)    0\n",
      "BO1017_Pressure(m)    0\n",
      "BO1021_FLOW1)         0\n",
      "BO1021_Pressure       0\n",
      "BO1022_flow1          0\n",
      "BO1022_Pressure(m)    0\n",
      "BO1017_FLOW1          0\n",
      "BO1029_FLOW1          0\n",
      "BO1029_Pressure(m)    0\n",
      "NB1013_FLOW1          0\n",
      "NB1017_FLOW1          0\n",
      "NB1017_Pressure       0\n",
      "NB1019_FLOW1          0\n",
      "NB1019_Pressure       0\n",
      "NB1020_FLOW1          0\n",
      "NB1021_FLOW1          0\n",
      "NB1022_FLOW1          0\n",
      "TD1029_flow1          0\n",
      "TD1029_Pressure       0\n",
      "TD1043_FLOW1          0\n",
      "TD1043_Press(m)       0\n",
      "NMNBOOTM1_FLOW1       0\n",
      "BOO_TM2_Pressure      0\n",
      "dtype: int64\n",
      "                BO1013_FLOW1  BO1016_Pressure(m)  BO1017_Pressure(m)  \\\n",
      "Date_time                                                              \n",
      "9/15/2023 0:00      0.463406            0.616835            0.374450   \n",
      "9/15/2023 0:05      0.459188            0.618765            0.379352   \n",
      "9/15/2023 0:10      0.454970            0.620694            0.384254   \n",
      "9/15/2023 0:15      0.450752            0.622623            0.389156   \n",
      "9/15/2023 0:20      0.447104            0.624264            0.393692   \n",
      "\n",
      "                BO1021_FLOW1)  BO1021_Pressure  BO1022_flow1  \\\n",
      "Date_time                                                      \n",
      "9/15/2023 0:00       0.384216         0.464074      0.278521   \n",
      "9/15/2023 0:05       0.378265         0.452804      0.261737   \n",
      "9/15/2023 0:10       0.372314         0.441533      0.244953   \n",
      "9/15/2023 0:15       0.366363         0.430262      0.228169   \n",
      "9/15/2023 0:20       0.367818         0.430544      0.229108   \n",
      "\n",
      "                BO1022_Pressure(m)  BO1017_FLOW1  BO1029_FLOW1  \\\n",
      "Date_time                                                        \n",
      "9/15/2023 0:00            0.648942      0.534745      0.224100   \n",
      "9/15/2023 0:05            0.650105      0.532980      0.214317   \n",
      "9/15/2023 0:10            0.651269      0.531216      0.204535   \n",
      "9/15/2023 0:15            0.652432      0.529451      0.194753   \n",
      "9/15/2023 0:20            0.657233      0.527686      0.194901   \n",
      "\n",
      "                BO1029_Pressure(m)  ...  NB1019_FLOW1  NB1019_Pressure  \\\n",
      "Date_time                           ...                                  \n",
      "9/15/2023 0:00            0.220722  ...      0.526155         0.671750   \n",
      "9/15/2023 0:05            0.224362  ...      0.509058         0.675304   \n",
      "9/15/2023 0:10            0.228003  ...      0.491961         0.678858   \n",
      "9/15/2023 0:15            0.231643  ...      0.474864         0.682412   \n",
      "9/15/2023 0:20            0.228405  ...      0.469826         0.686209   \n",
      "\n",
      "                NB1020_FLOW1  NB1021_FLOW1  NB1022_FLOW1  TD1029_flow1  \\\n",
      "Date_time                                                                \n",
      "9/15/2023 0:00      0.550383      0.402367      0.324510      0.258845   \n",
      "9/15/2023 0:05      0.535779      0.394477      0.314379      0.245858   \n",
      "9/15/2023 0:10      0.521176      0.386588      0.304248      0.232871   \n",
      "9/15/2023 0:15      0.506572      0.378698      0.294118      0.219884   \n",
      "9/15/2023 0:20      0.500183      0.380342      0.292810      0.210628   \n",
      "\n",
      "                TD1029_Pressure  TD1043_FLOW1  TD1043_Press(m)  \\\n",
      "Date_time                                                        \n",
      "9/15/2023 0:00         0.208977      0.349833         0.527473   \n",
      "9/15/2023 0:05         0.206798      0.333751         0.527473   \n",
      "9/15/2023 0:10         0.204620      0.317669         0.527473   \n",
      "9/15/2023 0:15         0.202441      0.301587         0.527473   \n",
      "9/15/2023 0:20         0.204534      0.295252         0.527473   \n",
      "\n",
      "                NMNBOOTM1_FLOW1  \n",
      "Date_time                        \n",
      "9/15/2023 0:00         0.589806  \n",
      "9/15/2023 0:05         0.575243  \n",
      "9/15/2023 0:10         0.560680  \n",
      "9/15/2023 0:15         0.546117  \n",
      "9/15/2023 0:20         0.542071  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"ALL_5T.csv\")\n",
    "df.head()\n",
    "print(df.isnull().sum())\n",
    "#xử lí giá trị âm\n",
    "colum_press = ['BO1016_Pressure(m)', 'BO1017_Pressure(m)', 'BO1021_Pressure', 'BO1022_Pressure(m)', 'BO1029_Pressure(m)', 'NB1019_Pressure', 'TD1029_Pressure', 'TD1043_Press(m)']\n",
    "df[colum_press] = df[colum_press].apply(lambda x:x+5)\n",
    "df.describe()\n",
    "#tách tập trạng thái và tập điều khiển\n",
    "df.set_index(\"Date_time\", inplace=True) #set index\n",
    "control = df[\"BOO_TM2_Pressure\"]\n",
    "state_ = df.drop([ \"BOO_TM2_Pressure\"], axis = 1)\n",
    "features = state_.columns\n",
    "scaler =MMS() #scale data\n",
    "state = scaler.fit_transform(state_[features])\n",
    "state = pd.DataFrame(columns=features, data=state, index = df.index)\n",
    "print(state.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f3a410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31384, 5, 23)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LSTM1 áp dụng lên tập state, window = 5'''\n",
    "X = []\n",
    "Y = []\n",
    "u_control = []\n",
    "# Loop qua các hàng của dataframe để lấy các cửa sổ thời gian t-5 đến t và giá trị tại t+1 cho Y\n",
    "for i in range(5, len(df) - 1):\n",
    "    X.append(state.iloc[i-5:i].values)  # Lấy cửa sổ thời gian state[0:5] ; state[5]\n",
    "    Y.append(state.iloc[i])  # Lấy giá trị t+1 của state\n",
    "    u_control.append(control.iloc[i])# Lấy giá trị t+1 của control\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a88068e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 5, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_state_tr , y_state_tr = X[0:18000] , Y[0:18000]\n",
    "X_state_te, y_state_te = X[18000:], Y[18000:]\n",
    "# y_control_tr ,y_state_test, y_control_test = Y_control[7500:9000], Y_control[9000:]\n",
    "# '''y_state_te + y_control_tr làm nguyên liệu train cho mode regressor, y_ '''\n",
    "X_state_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c60cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# tạo biến thử\n",
    "dense_act3 = ['ReLU', 'elu', 'tanh', 'sigmoid', 'selu'] \n",
    "recur_act3 = ['ReLU', 'elu', 'tanh', 'sigmoid', 'selu']\n",
    "epoch3 = [100]\n",
    "# epoch = [100, 256, 500]\n",
    "learning_r3 = [0.001]\n",
    "# learning_r = [0.0005, 0.001, 0.002] \n",
    "ls = 'mae'\n",
    "# ls = ['mae', 'mse']\n",
    "'''opt1 = SGD()\n",
    "opt2 = Adam()'''\n",
    "print('yes')\n",
    "kind = []\n",
    "sc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700a430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 5, 23), found shape=(None, 5, 24)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m      6\u001b[0m model3 \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      7\u001b[0m          tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m128\u001b[39m, recurrent_activation \u001b[38;5;241m=\u001b[39m j, input_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m23\u001b[39m]),\n\u001b[0;32m      8\u001b[0m          tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m          tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m23\u001b[39m)\n\u001b[0;32m     13\u001b[0m          ])\n\u001b[0;32m     14\u001b[0m model3\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m opt, loss \u001b[38;5;241m=\u001b[39m ls, )\n\u001b[1;32m---> 15\u001b[0m apply3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_state_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_state_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_act3 \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m recur_act3 \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m j \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m epoch3: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(m) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ls \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(n)\n\u001b[0;32m     17\u001b[0m score \u001b[38;5;241m=\u001b[39m model3\u001b[38;5;241m.\u001b[39mevaluate(X_state_te, y_state_te)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewfeygdip.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ainzo\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 5, 23), found shape=(None, 5, 24)\n"
     ]
    }
   ],
   "source": [
    "for i in dense_act3:\n",
    "    for j in recur_act3:\n",
    "        for m in epoch3:\n",
    "            for n in learning_r3:\n",
    "                opt = Adam(learning_rate= n)\n",
    "                model3 = Sequential([\n",
    "                         tf.keras.layers.LSTM(128, recurrent_activation = j, input_shape = [5, 23]),\n",
    "                         tf.keras.layers.Dropout(0.1),\n",
    "                         tf.keras.layers.Dense(64, activation = i),\n",
    "                         tf.keras.layers.Dropout(0.1),\n",
    "                         tf.keras.layers.Dense(32, activation = i),\n",
    "                         tf.keras.layers.Dense(23)\n",
    "                         ])\n",
    "                model3.compile(optimizer = opt, loss = ls, )\n",
    "                apply3 = model3.fit(X_state_tr, y_state_tr, batch_size = 128, epochs = m, validation_split = 0.2)\n",
    "                name = \"model: \"+ \"dense_act3 \"+ i+ \" recur_act3 \"+ j + \" epoch3: \" + str(m) +\" ls \"+ str(n)\n",
    "                score = model3.evaluate(X_state_te, y_state_te)\n",
    "                kind.append(name)\n",
    "                sc.append(score)\n",
    "a = np.min(sc)\n",
    "b = sc.index(a)\n",
    "print(\"loss_min \"+str(a))\n",
    "print(kind[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605bd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Model_hyper2'''\n",
    "# dense_act4 = [ 'tanh', 'sigmoid', 'selu'] \n",
    "# recur_act4 = [ 'tanh', 'sigmoid', 'selu']\n",
    "# for i in dense_act4:\n",
    "#     for j in recur_act4:\n",
    "#         for m in epoch3:\n",
    "#             for n in learning_r3:\n",
    "#                 opt = SGD(learning_rate= n)\n",
    "#                 model3 = Sequential([\n",
    "#                          tf.keras.layers.LSTM(64, recurrent_activation = j, input_shape = [8, 1]),\n",
    "#                          tf.keras.layers.Dropout(0.1),\n",
    "#                          tf.keras.layers.Dense(32, activation = i),\n",
    "#                          tf.keras.layers.Dropout(0.1),\n",
    "#                          tf.keras.layers.Dense(16, activation = i),\n",
    "#                          tf.keras.layers.Dense(8, activation = i),\n",
    "#                          tf.keras.layers.Dense(1)\n",
    "#                          ])\n",
    "#                 model3.compile(optimizer = opt, loss = ls, )\n",
    "#                 apply3 = model3.fit(X_control_tr, y_control_tr, batch_size = 1024, epochs = m, validation_split = 0.2)\n",
    "#                 name = \"model: \"+ \"dense_act3 \"+ i+ \" recur_act3 \"+ j + \" epoch3: \" + str(m) +\" ls \"+ str(n)\n",
    "#                 score = model3.evaluate(X_control_te, y_control_te)\n",
    "#                 kind.append(name)\n",
    "#                 kind.append(score)\n",
    "#                 sc.append(score)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31008889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(learning_rate= 0.0002)\n",
    "# model4 = Sequential([\n",
    "#                          tf.keras.layers.LSTM(64, recurrent_activation = 'relu', input_shape = [8, 1]),\n",
    "#                          tf.keras.layers.Dropout(0.1),\n",
    "#                          tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "#                          tf.keras.layers.Dropout(0.1),\n",
    "#                          tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "#                          tf.keras.layers.Dense(8, activation = 'sigmoid'),\n",
    "#                          tf.keras.layers.Dense(1)\n",
    "#                          ])\n",
    "# # cp2 = ModelCheckpoint('model_hyper2_1/', loss = 'mae', save_best_only = True)\n",
    "# model4.compile(optimizer = opt, loss = 'mae', )\n",
    "# apply4 = model4.fit(X_control_tr, y_control_tr, batch_size = 1024, epochs = 1000, validation_split = 0.2)\n",
    "# # name = \"model: \"+ \"dense_act3 \"+ i+ \" recur_act3 \"+ j + \" epoch3: \" + str(m) +\" ls \"+ str(n)\n",
    "# score = model4.evaluate(X_control_te, y_control_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74688763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 6s 13ms/step - loss: 0.1699 - val_loss: 0.0620\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0731 - val_loss: 0.0524\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0569 - val_loss: 0.0442\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0487 - val_loss: 0.0379\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0434 - val_loss: 0.0357\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0396 - val_loss: 0.0331\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0370 - val_loss: 0.0315\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0344 - val_loss: 0.0297\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0324 - val_loss: 0.0279\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0310 - val_loss: 0.0270\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0294 - val_loss: 0.0256\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0283 - val_loss: 0.0252\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0270 - val_loss: 0.0241\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0259 - val_loss: 0.0232\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0250 - val_loss: 0.0226\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0244 - val_loss: 0.0230\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0238 - val_loss: 0.0218\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0228 - val_loss: 0.0213\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0223 - val_loss: 0.0204\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0215 - val_loss: 0.0206\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0210 - val_loss: 0.0202\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0206 - val_loss: 0.0191\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0200 - val_loss: 0.0190\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0195 - val_loss: 0.0185\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0182 - val_loss: 0.0170\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0177 - val_loss: 0.0169\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0174 - val_loss: 0.0161\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0173 - val_loss: 0.0160\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0168 - val_loss: 0.0162\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0167 - val_loss: 0.0153\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0166 - val_loss: 0.0159\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0162 - val_loss: 0.0145\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0161 - val_loss: 0.0148\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0160 - val_loss: 0.0142\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0161 - val_loss: 0.0146\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0157 - val_loss: 0.0152\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0156 - val_loss: 0.0142\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0155 - val_loss: 0.0134\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0155 - val_loss: 0.0139\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0154 - val_loss: 0.0139\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0154 - val_loss: 0.0134\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0153 - val_loss: 0.0140\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0152 - val_loss: 0.0131\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0151 - val_loss: 0.0130\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0135\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.0125\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0127\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0132\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0127\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0150 - val_loss: 0.0138\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0132\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0148 - val_loss: 0.0124\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0119\n",
      "Epoch 85/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 86/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 87/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 88/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 89/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 90/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 91/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0146 - val_loss: 0.0119\n",
      "Epoch 92/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 93/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 94/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 95/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 96/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 97/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 98/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 99/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 100/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 101/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 102/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0122\n",
      "Epoch 103/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 104/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 105/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 106/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 107/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.0117\n",
      "Epoch 108/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 109/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 110/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0144 - val_loss: 0.0127\n",
      "Epoch 111/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 112/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 113/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 114/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 115/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 116/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 117/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 118/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 119/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 120/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 121/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 122/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 123/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 124/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 125/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 126/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 127/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 128/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 129/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 130/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 131/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 132/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 133/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 134/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 135/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 136/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 137/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 138/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 139/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 140/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 141/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 142/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 143/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0141 - val_loss: 0.0119\n",
      "Epoch 144/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 145/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 146/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 147/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 148/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 149/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 150/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 151/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 152/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 153/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 154/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 155/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 156/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 157/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 158/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 160/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 161/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 162/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 163/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 164/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 165/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 166/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 167/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 168/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 169/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 170/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 171/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 172/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0136 - val_loss: 0.0119\n",
      "Epoch 173/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 174/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 175/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0119\n",
      "Epoch 176/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 177/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 178/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 179/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 180/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 181/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 182/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 183/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 184/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 185/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0119\n",
      "Epoch 186/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 187/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 188/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 189/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 190/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 191/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 192/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 193/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 194/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 195/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 196/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 197/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 198/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 199/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 200/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 201/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 202/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 203/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 204/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 205/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 206/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 207/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 208/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 209/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 210/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 211/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 212/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 213/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 214/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 215/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 216/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 217/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 218/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 219/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 220/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 221/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 222/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 223/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 224/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 225/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 226/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 227/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 228/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 229/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 230/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 231/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0128\n",
      "Epoch 232/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 233/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 234/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 235/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 236/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 237/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 238/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 239/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 240/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 241/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 242/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 243/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 244/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 245/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 246/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 247/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 248/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 249/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 250/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 251/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 252/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 253/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 254/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 255/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 256/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 257/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 258/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 259/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 260/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 261/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 262/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 263/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 264/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 265/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 266/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 267/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 268/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 269/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 270/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 271/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 272/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 273/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0114 - val_loss: 0.0124\n",
      "Epoch 274/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 275/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 276/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 277/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 278/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 279/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 280/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 281/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 282/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 283/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 284/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 285/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 286/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 287/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 288/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 289/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 290/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 291/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 292/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 293/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 294/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 295/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 296/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 297/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 298/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 299/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 300/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 301/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 302/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 303/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 304/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 305/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 306/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 307/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 308/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 309/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 310/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 311/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 312/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 313/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 314/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 315/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 316/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 317/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 318/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 319/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 320/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 321/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 322/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 323/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 324/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 325/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 326/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 327/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 328/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 329/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 330/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 331/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 332/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 333/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 334/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 335/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 336/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 337/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 338/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 339/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 340/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 341/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 342/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 343/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 344/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 345/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 346/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 347/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 348/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 349/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 350/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 351/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 352/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 353/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 354/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 355/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 356/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 357/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 358/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 359/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 360/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 361/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 362/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 363/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 364/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 365/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 366/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 367/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 368/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 369/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 370/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 371/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 372/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 373/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 374/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 375/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 376/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 377/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 378/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 379/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 380/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 381/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 382/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 383/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 384/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 385/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 386/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 387/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 388/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 389/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 390/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 391/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 392/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 393/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 394/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 395/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 396/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 397/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 398/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 399/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 400/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 401/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 402/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 403/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 404/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 405/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 406/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 407/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 408/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 409/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 410/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 411/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 412/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 413/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 414/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 415/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 416/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 417/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 418/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 419/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 420/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 421/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 422/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 423/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 424/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 425/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 426/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 427/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 428/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 429/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 430/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 431/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 432/1000\n",
      "225/225 [==============================] - 3s 16ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 433/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 434/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 435/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 436/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 437/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 438/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 439/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 440/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 441/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 442/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 443/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 444/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 445/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 446/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 447/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 448/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 449/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 450/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 451/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 452/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 453/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 454/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 455/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 456/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 457/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 458/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 459/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 460/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 461/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 462/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 463/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 464/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 465/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 466/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 467/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 468/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 469/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 470/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 471/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 472/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 473/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 474/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 475/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 476/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 477/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 478/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 479/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 480/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 481/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 482/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 483/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 484/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 485/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 486/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 487/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 488/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 489/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 490/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 491/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 492/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 493/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 494/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 495/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 496/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 497/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 498/1000\n",
      "225/225 [==============================] - 4s 19ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 499/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 500/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 501/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 502/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 503/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 504/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 505/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 506/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 507/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 508/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 509/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 510/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 511/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 512/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 513/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 514/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 515/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 516/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 517/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 518/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 519/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 520/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 521/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 522/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 523/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 524/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 525/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 526/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 527/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 528/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 529/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 530/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 531/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 532/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 533/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 534/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 535/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 536/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 537/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 538/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 539/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 540/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 541/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 542/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 543/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 544/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 545/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 546/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 547/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 548/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 549/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 550/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 551/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 552/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 553/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 554/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 555/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 556/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 557/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 558/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 559/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 560/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 561/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 562/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 563/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 564/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 565/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 566/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 567/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 568/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 569/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 570/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 571/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 572/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 573/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 574/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 575/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 576/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 577/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 578/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 579/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 580/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 581/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 582/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 583/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 584/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 585/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 586/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 587/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 588/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 589/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 590/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 591/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 592/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 593/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 594/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 595/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 596/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 597/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 598/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 599/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 600/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 601/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 602/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 603/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 604/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 605/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 606/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 607/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 608/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 609/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 610/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 611/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 612/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 613/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 614/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 615/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 616/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 617/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 618/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 619/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 620/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 621/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 622/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 623/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 624/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 625/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 626/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 627/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 628/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 629/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 630/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 631/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 632/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 633/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 634/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 635/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 636/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 637/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 638/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 639/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 640/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 641/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 642/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 643/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 644/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 645/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 646/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 647/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 648/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 649/1000\n",
      "225/225 [==============================] - 6s 27ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 650/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 651/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 652/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 653/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 654/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 655/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 656/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 657/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 658/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 659/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 660/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 661/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 662/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 663/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 664/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 665/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 666/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 667/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 668/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 669/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 670/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 671/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 672/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 673/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 674/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 675/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 676/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 677/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 678/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 679/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 680/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 681/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 682/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 683/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 684/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 685/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 686/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 687/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 688/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0113\n",
      "Epoch 689/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 690/1000\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 691/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 692/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 693/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 694/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 695/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 696/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 697/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 698/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 699/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 700/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 701/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 702/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 703/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 704/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 705/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 706/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 707/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 708/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 709/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 710/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 711/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 712/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 713/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 714/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 715/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 716/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 717/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 718/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 719/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 720/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 721/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 722/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 723/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 724/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 725/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 726/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 727/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 728/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 729/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 730/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 731/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 732/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 733/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 734/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 735/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 736/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 737/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 738/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 739/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 740/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 741/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 742/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 743/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 744/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 745/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 746/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 747/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 748/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 749/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 750/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 751/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 752/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 753/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 754/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 755/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 756/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 757/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 758/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 759/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 760/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 761/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 762/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 763/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 764/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 765/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 766/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 767/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 768/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 769/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 770/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 771/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 772/1000\n",
      "225/225 [==============================] - 4s 20ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 773/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 774/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 775/1000\n",
      "225/225 [==============================] - 4s 19ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 776/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 777/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 778/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 779/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 780/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 781/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 782/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 783/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 784/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 785/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 786/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 787/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 788/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 789/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 790/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 791/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 792/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 793/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 794/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 795/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 796/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 797/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 798/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 799/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 800/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 801/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 802/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 803/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 804/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 805/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 806/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 807/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 808/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 809/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 810/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 811/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 812/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 813/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 814/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 815/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 816/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 817/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 818/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 819/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 820/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 821/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 822/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 823/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 824/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 825/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 826/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 827/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 828/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 829/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 830/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 831/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 832/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 833/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 834/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 835/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 836/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 837/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 838/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 839/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 840/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 841/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 842/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 843/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 844/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 845/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 846/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 847/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 848/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 849/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 850/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 851/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 852/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 853/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 854/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 855/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 856/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 857/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 858/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 859/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 860/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 861/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 862/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 863/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 864/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 865/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 866/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 867/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 868/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 869/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 870/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 871/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 872/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 873/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 874/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 875/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 876/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 877/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 878/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 879/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 880/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 881/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 882/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 883/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 884/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 885/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 886/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 887/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 888/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 889/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 890/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 891/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 892/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 893/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 894/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 895/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 896/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 897/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 898/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 899/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 900/1000\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 901/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 902/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 903/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 904/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 905/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 906/1000\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 907/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 908/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 909/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 910/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 911/1000\n",
      "225/225 [==============================] - 3s 11ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 912/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 913/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 914/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 915/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 916/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 917/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 918/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 919/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 920/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 921/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 922/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 923/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 924/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 925/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 926/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 927/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 928/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 929/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 930/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 931/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 932/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 933/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 934/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 935/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 936/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 937/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 938/1000\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 940/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 941/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 942/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 943/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 944/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 945/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 946/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 947/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 948/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 949/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 950/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 951/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 952/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 953/1000\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 954/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 955/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 956/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 957/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 958/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 959/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 960/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 961/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 962/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 963/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 964/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 965/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 966/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 967/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 968/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 969/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 970/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 971/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 972/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 973/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 974/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 975/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 976/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 977/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 978/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 979/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 980/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 981/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 982/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 983/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 984/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 985/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 986/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 987/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 988/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 989/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 990/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 991/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 992/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 993/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 994/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0103\n",
      "Epoch 995/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 996/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 997/1000\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 998/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 999/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 1000/1000\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "419/419 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "'''After hyper: tanh - sigmoid - 100 - 0.0002'''\n",
    "opt = Adam(learning_rate= 0.0002)\n",
    "model5 = Sequential([\n",
    "                         tf.keras.layers.LSTM(128, recurrent_activation = 'sigmoid', input_shape = [5, 23]),\n",
    "                         tf.keras.layers.Dropout(0.1),\n",
    "                         tf.keras.layers.Dense(64, activation = 'tanh'),\n",
    "                         tf.keras.layers.Dropout(0.1),\n",
    "                         tf.keras.layers.Dense(32, activation = 'tanh'),\n",
    "                         tf.keras.layers.Dense(23)\n",
    "                         ])\n",
    "model5.compile(optimizer = opt, loss = ls, )\n",
    "apply5 = model5.fit(X_state_tr, y_state_tr, batch_size = 64, epochs = 1000, validation_split = 0.2)\n",
    "Y_pre = model5.predict(X_state_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1b16de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13384, 23)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pre.shape)\n",
    "# sử dụng Y_pre[6000:9000] và u_control[6000:9000] để train cho model hồi quy\n",
    "Y_re_train = Y_pre[0:9000]\n",
    "u_re_train = u_control[18000:27000]\n",
    "Y_re_te = Y_pre[9000:]\n",
    "u_re_te = u_control[27000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ee175d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.885 total time=   1.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.809 total time=   0.9s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.925 total time=   1.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.895 total time=   1.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.887 total time=   1.1s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.910 total time=   1.6s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.775 total time=   1.2s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.922 total time=   1.7s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.914 total time=   1.4s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.888 total time=   1.5s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.859 total time=   0.8s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.781 total time=   1.0s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.906 total time=   1.0s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.867 total time=   0.8s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.865 total time=   0.9s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.032 total time=   3.2s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.022 total time=   3.1s\n",
      "[CV 3/5] END ...C=10, gamma=0.001, kernel=poly;, score=-0.052 total time=   2.2s\n",
      "[CV 4/5] END ...C=10, gamma=0.001, kernel=poly;, score=-0.077 total time=   2.5s\n",
      "[CV 5/5] END ...C=10, gamma=0.001, kernel=poly;, score=-0.074 total time=   2.1s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.698 total time=   2.2s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.648 total time=   2.4s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.745 total time=   2.4s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.696 total time=   2.5s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.688 total time=   1.9s\n",
      "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.910 total time=   1.5s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.775 total time=   1.2s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.922 total time=   1.6s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.914 total time=   1.4s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.888 total time=   1.2s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.578 total time=   2.2s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.539 total time=   2.2s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.611 total time=   2.0s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.558 total time=   1.7s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.552 total time=   1.6s\n",
      "[CV 1/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.021 total time=   2.4s\n",
      "[CV 2/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.026 total time=   2.3s\n",
      "[CV 3/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.113 total time=   2.6s\n",
      "[CV 4/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.141 total time=   2.7s\n",
      "[CV 5/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.143 total time=   2.3s\n",
      "[CV 1/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.858 total time=   1.2s\n",
      "[CV 2/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.781 total time=   1.6s\n",
      "[CV 3/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.906 total time=   1.3s\n",
      "[CV 4/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.868 total time=   1.3s\n",
      "[CV 5/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.865 total time=   1.1s\n",
      "[CV 1/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.908 total time=   1.1s\n",
      "[CV 2/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.776 total time=   0.8s\n",
      "[CV 3/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.923 total time=   1.5s\n",
      "[CV 4/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.914 total time=   1.3s\n",
      "[CV 5/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.888 total time=   1.0s\n",
      "[CV 1/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.811 total time=   1.6s\n",
      "[CV 2/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.745 total time=   1.4s\n",
      "[CV 3/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.864 total time=   1.2s\n",
      "[CV 4/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.821 total time=   1.0s\n",
      "[CV 5/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.816 total time=   0.9s\n",
      "[CV 1/5] END .....C=5, gamma=0.001, kernel=poly;, score=0.006 total time=   2.0s\n",
      "[CV 2/5] END ....C=5, gamma=0.001, kernel=poly;, score=-0.001 total time=   2.4s\n",
      "[CV 3/5] END ....C=5, gamma=0.001, kernel=poly;, score=-0.077 total time=   2.9s\n",
      "[CV 4/5] END ....C=5, gamma=0.001, kernel=poly;, score=-0.105 total time=   2.4s\n",
      "[CV 5/5] END ....C=5, gamma=0.001, kernel=poly;, score=-0.102 total time=   2.1s\n",
      "[CV 1/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.578 total time=   2.4s\n",
      "[CV 2/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.539 total time=   2.6s\n",
      "[CV 3/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.611 total time=   2.8s\n",
      "[CV 4/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.558 total time=   2.4s\n",
      "[CV 5/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.551 total time=   2.6s\n",
      "[CV 1/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.908 total time=   1.3s\n",
      "[CV 2/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.776 total time=   0.9s\n",
      "[CV 3/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.923 total time=   1.2s\n",
      "[CV 4/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.914 total time=   1.3s\n",
      "[CV 5/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.888 total time=   0.9s\n",
      "[CV 1/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.468 total time=   1.8s\n",
      "[CV 2/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.442 total time=   1.8s\n",
      "[CV 3/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.484 total time=   1.8s\n",
      "[CV 4/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.434 total time=   2.2s\n",
      "[CV 5/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.423 total time=   2.1s\n",
      "[CV 1/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.021 total time=   2.5s\n",
      "[CV 2/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.026 total time=   2.4s\n",
      "[CV 3/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.113 total time=   2.3s\n",
      "[CV 4/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.142 total time=   2.3s\n",
      "[CV 5/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.143 total time=   2.4s\n",
      "[CV 1/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.790 total time=   2.1s\n",
      "[CV 2/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.726 total time=   2.0s\n",
      "[CV 3/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.843 total time=   1.8s\n",
      "[CV 4/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.799 total time=   1.7s\n",
      "[CV 5/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.908 total time=   0.8s\n",
      "[CV 2/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.924 total time=   1.0s\n",
      "[CV 4/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.913 total time=   0.8s\n",
      "[CV 5/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.888 total time=   0.6s\n",
      "[CV 1/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.699 total time=   1.7s\n",
      "[CV 2/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.647 total time=   1.8s\n",
      "[CV 3/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.745 total time=   2.0s\n",
      "[CV 4/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.696 total time=   1.8s\n",
      "[CV 5/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.688 total time=   1.6s\n",
      "[CV 1/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.009 total time=   2.3s\n",
      "[CV 2/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.016 total time=   2.1s\n",
      "[CV 3/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.094 total time=   2.5s\n",
      "[CV 4/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.122 total time=   3.6s\n",
      "[CV 5/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.124 total time=   2.8s\n",
      "[CV 1/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.437 total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.414 total time=   2.9s\n",
      "[CV 3/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.446 total time=   2.5s\n",
      "[CV 4/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.397 total time=   2.7s\n",
      "[CV 5/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.387 total time=   2.9s\n",
      "[CV 1/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.908 total time=   0.9s\n",
      "[CV 2/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.924 total time=   0.9s\n",
      "[CV 4/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.913 total time=   0.7s\n",
      "[CV 5/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.888 total time=   0.6s\n",
      "[CV 1/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.350 total time=   2.0s\n",
      "[CV 2/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.336 total time=   2.0s\n",
      "[CV 3/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.340 total time=   1.9s\n",
      "[CV 4/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.291 total time=   2.1s\n",
      "[CV 5/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.282 total time=   2.3s\n",
      "[CV 1/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.021 total time=   2.8s\n",
      "[CV 2/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.026 total time=   2.6s\n",
      "[CV 3/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.113 total time=   2.4s\n",
      "[CV 4/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.142 total time=   2.2s\n",
      "[CV 5/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.143 total time=   2.1s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.699 total time=   2.1s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.648 total time=   2.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.745 total time=   1.8s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.696 total time=   2.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.688 total time=   1.9s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.907 total time=   0.6s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.784 total time=   0.5s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.925 total time=   1.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.914 total time=   0.8s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.890 total time=   0.6s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.578 total time=   1.7s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.539 total time=   2.3s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.611 total time=   2.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.558 total time=   1.5s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.552 total time=   1.4s\n",
      "[CV 1/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.014 total time=   2.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.021 total time=   2.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.103 total time=   2.1s\n",
      "[CV 4/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.131 total time=   2.3s\n",
      "[CV 5/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.133 total time=   2.7s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.350 total time=   2.8s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.336 total time=   2.5s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.340 total time=   2.4s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.291 total time=   2.5s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.282 total time=   2.8s\n",
      "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.907 total time=   0.9s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.784 total time=   0.7s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.925 total time=   0.9s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.914 total time=   0.8s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.890 total time=   0.6s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.274 total time=   2.2s\n",
      "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.264 total time=   2.1s\n",
      "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   1.9s\n",
      "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.206 total time=   2.0s\n",
      "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.197 total time=   1.9s\n",
      "[CV 1/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.021 total time=   2.2s\n",
      "[CV 2/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.026 total time=   2.6s\n",
      "[CV 3/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.113 total time=   2.4s\n",
      "[CV 4/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.142 total time=   2.2s\n",
      "[CV 5/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.143 total time=   2.3s\n",
      "[CV 1/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.578 total time=   2.3s\n",
      "[CV 2/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.539 total time=   3.5s\n",
      "[CV 3/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.610 total time=   2.5s\n",
      "[CV 4/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.558 total time=   2.6s\n",
      "[CV 5/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.552 total time=   2.0s\n",
      "[CV 1/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.908 total time=   0.5s\n",
      "[CV 2/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.799 total time=   0.4s\n",
      "[CV 3/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.926 total time=   0.5s\n",
      "[CV 4/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.915 total time=   0.5s\n",
      "[CV 5/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.891 total time=   0.4s\n",
      "[CV 1/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.468 total time=   1.5s\n",
      "[CV 2/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.442 total time=   1.6s\n",
      "[CV 3/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.484 total time=   2.1s\n",
      "[CV 4/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.434 total time=   2.2s\n",
      "[CV 5/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.423 total time=   2.0s\n",
      "[CV 1/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.017 total time=   2.2s\n",
      "[CV 2/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.023 total time=   2.3s\n",
      "[CV 3/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.108 total time=   2.4s\n",
      "[CV 4/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.137 total time=   2.7s\n",
      "[CV 5/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.139 total time=   2.6s\n",
      "[CV 1/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.274 total time=   2.9s\n",
      "[CV 2/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.264 total time=   2.7s\n",
      "[CV 3/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.252 total time=   2.6s\n",
      "[CV 4/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.206 total time=   2.5s\n",
      "[CV 5/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.197 total time=   2.6s\n",
      "[CV 1/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.908 total time=   0.6s\n",
      "[CV 2/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.799 total time=   0.5s\n",
      "[CV 3/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.926 total time=   0.6s\n",
      "[CV 4/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.915 total time=   0.6s\n",
      "[CV 5/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.891 total time=   0.5s\n",
      "[CV 1/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.205 total time=   2.2s\n",
      "[CV 2/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.199 total time=   2.1s\n",
      "[CV 3/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.165 total time=   2.0s\n",
      "[CV 4/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.123 total time=   2.1s\n",
      "[CV 5/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.117 total time=   2.0s\n",
      "[CV 1/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.021 total time=   2.1s\n",
      "[CV 2/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.026 total time=   2.4s\n",
      "[CV 3/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.113 total time=   2.3s\n",
      "[CV 4/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.142 total time=   2.0s\n",
      "[CV 5/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.143 total time=   2.0s\n",
      "SVR(C=0.5, gamma=0.001, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "'''build thành phần regression'''\n",
    "# tach X_svr, y_svr, state, control\n",
    "'''Thử với SVR: lấy y_pre và u để train'''\n",
    "param_grid = {'C': [10, 5, 2, 1, 0.5],  \n",
    "              'gamma': [ 0.001, 0.0001], \n",
    "              'kernel': ['rbf','linear','sigmoid','poly']\n",
    "               }  \n",
    "X_svr = state\n",
    "y_svr = control\n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3, error_score='raise')   \n",
    "# fitting the model for grid search \n",
    "grid.fit(Y_re_train, u_re_train) \n",
    "print(grid.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "453e1fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'gamma': 0.001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88668150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07336332971328041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hơi tệ :v'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_svr = SVR(C=0.5, kernel = 'linear', gamma = 0.001,)\n",
    "model_svr.fit(Y_re_train, u_re_train)\n",
    "y_pre_svr = model_svr.predict(Y_re_te)\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "def plot_predictions1(model, X, y, start=0, end=100):\n",
    "    predictions = model.predict(X).flatten()\n",
    "    df = pd.DataFrame(data={'Predictions':predictions, 'Actuals':y})\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(df['Predictions'][start:end], label = 'Pre')\n",
    "    plt.plot(df['Actuals'][start:end], label = 'Actual')\n",
    "    plt.legend()\n",
    "    return df, mae(y, predictions)\n",
    "plot_predictions1(model_svr, Y_re_te, u_re_te, start=0, end=50)\n",
    "print(mae(u_re_te, y_pre_svr))\n",
    "'''hơi tệ :v'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaa9ad09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.007 total time=  18.9s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.814 total time=  21.1s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.807 total time=  21.4s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.810 total time=  20.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.799 total time=  19.8s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=linear;, score=-0.066 total time=  25.6s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.819 total time=  31.1s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.827 total time=  32.2s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.022 total time=  25.5s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.784 total time=  27.2s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.056 total time=  12.9s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.805 total time=  14.7s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.794 total time=  13.2s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.802 total time=  13.1s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.800 total time=  13.3s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.076 total time=  27.7s\n",
      "[CV 2/5] END ...C=10, gamma=0.001, kernel=poly;, score=-0.017 total time=  28.5s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.057 total time=  29.9s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.065 total time=  28.8s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.106 total time=  37.6s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.318 total time=  19.6s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.764 total time=  19.6s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.741 total time=  19.4s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.767 total time=  19.6s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.792 total time=  20.6s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=linear;, score=-0.066 total time=  29.6s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.819 total time=  38.5s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.827 total time=  42.3s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.022 total time=  29.0s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.784 total time=  26.8s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.478 total time=  15.5s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.718 total time=  16.3s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.690 total time=  20.0s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.731 total time=  41.5s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.757 total time=  15.3s\n",
      "[CV 1/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.106 total time=  30.8s\n",
      "[CV 2/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.166 total time=  30.9s\n",
      "[CV 3/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.055 total time=  30.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.063 total time=  31.1s\n",
      "[CV 5/5] END ..C=10, gamma=0.0001, kernel=poly;, score=-0.029 total time=  30.2s\n",
      "[CV 1/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.058 total time=  14.5s\n",
      "[CV 2/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.806 total time=  20.6s\n",
      "[CV 3/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.795 total time=  17.6s\n",
      "[CV 4/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.802 total time=  17.8s\n",
      "[CV 5/5] END ......C=5, gamma=0.001, kernel=rbf;, score=0.801 total time=  17.6s\n",
      "[CV 1/5] END ..C=5, gamma=0.001, kernel=linear;, score=-0.067 total time=  16.8s\n",
      "[CV 2/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.819 total time=  21.9s\n",
      "[CV 3/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.827 total time=  20.1s\n",
      "[CV 4/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.127 total time=  20.2s\n",
      "[CV 5/5] END ...C=5, gamma=0.001, kernel=linear;, score=0.784 total time=  22.6s\n",
      "[CV 1/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.141 total time=  13.7s\n",
      "[CV 2/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.793 total time=  16.9s\n",
      "[CV 3/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.779 total time=  15.8s\n",
      "[CV 4/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.790 total time=  17.0s\n",
      "[CV 5/5] END ..C=5, gamma=0.001, kernel=sigmoid;, score=0.801 total time=  16.1s\n",
      "[CV 1/5] END .....C=5, gamma=0.001, kernel=poly;, score=0.005 total time= 1.1min\n",
      "[CV 2/5] END ....C=5, gamma=0.001, kernel=poly;, score=-0.077 total time= 1.2min\n",
      "[CV 3/5] END .....C=5, gamma=0.001, kernel=poly;, score=0.012 total time= 1.1min\n",
      "[CV 4/5] END .....C=5, gamma=0.001, kernel=poly;, score=0.012 total time= 1.2min\n",
      "[CV 5/5] END .....C=5, gamma=0.001, kernel=poly;, score=0.054 total time= 1.2min\n",
      "[CV 1/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.477 total time=  45.4s\n",
      "[CV 2/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.719 total time=  49.7s\n",
      "[CV 3/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.690 total time= 1.0min\n",
      "[CV 4/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.731 total time=  58.4s\n",
      "[CV 5/5] END .....C=5, gamma=0.0001, kernel=rbf;, score=0.757 total time=  48.7s\n",
      "[CV 1/5] END .C=5, gamma=0.0001, kernel=linear;, score=-0.067 total time=  37.5s\n",
      "[CV 2/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.819 total time=  51.8s\n",
      "[CV 3/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.827 total time=  48.7s\n",
      "[CV 4/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.127 total time=  44.0s\n",
      "[CV 5/5] END ..C=5, gamma=0.0001, kernel=linear;, score=0.784 total time=  44.3s\n",
      "[CV 1/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.614 total time=  41.4s\n",
      "[CV 2/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.647 total time=  41.7s\n",
      "[CV 3/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.619 total time=  37.7s\n",
      "[CV 4/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.670 total time=  42.9s\n",
      "[CV 5/5] END .C=5, gamma=0.0001, kernel=sigmoid;, score=0.687 total time=  41.9s\n",
      "[CV 1/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.106 total time= 1.2min\n",
      "[CV 2/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.166 total time=  51.4s\n",
      "[CV 3/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.055 total time=  29.9s\n",
      "[CV 4/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.063 total time=  30.7s\n",
      "[CV 5/5] END ...C=5, gamma=0.0001, kernel=poly;, score=-0.029 total time=  32.9s\n",
      "[CV 1/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.186 total time=  16.9s\n",
      "[CV 2/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.788 total time=  21.3s\n",
      "[CV 3/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.774 total time=  18.3s\n",
      "[CV 4/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.786 total time=  18.1s\n",
      "[CV 5/5] END ......C=2, gamma=0.001, kernel=rbf;, score=0.800 total time=  18.8s\n",
      "[CV 1/5] END ..C=2, gamma=0.001, kernel=linear;, score=-0.066 total time=  15.1s\n",
      "[CV 2/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.820 total time=  15.9s\n",
      "[CV 3/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.827 total time=  14.4s\n",
      "[CV 4/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.341 total time=  13.2s\n",
      "[CV 5/5] END ...C=2, gamma=0.001, kernel=linear;, score=0.785 total time=  14.4s\n",
      "[CV 1/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.317 total time=28.6min\n",
      "[CV 2/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.764 total time=  18.9s\n",
      "[CV 3/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.742 total time=  14.7s\n",
      "[CV 4/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.767 total time=  16.8s\n",
      "[CV 5/5] END ..C=2, gamma=0.001, kernel=sigmoid;, score=0.792 total time=  14.9s\n",
      "[CV 1/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.056 total time=  33.9s\n",
      "[CV 2/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.125 total time=  58.5s\n",
      "[CV 3/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.025 total time=  55.9s\n",
      "[CV 4/5] END ....C=2, gamma=0.001, kernel=poly;, score=-0.032 total time=  56.7s\n",
      "[CV 5/5] END .....C=2, gamma=0.001, kernel=poly;, score=0.008 total time=  56.7s\n",
      "[CV 1/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.633 total time=  44.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.616 total time=  45.1s\n",
      "[CV 3/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.589 total time=  46.5s\n",
      "[CV 4/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.645 total time=  45.4s\n",
      "[CV 5/5] END .....C=2, gamma=0.0001, kernel=rbf;, score=0.658 total time=  45.1s\n",
      "[CV 1/5] END .C=2, gamma=0.0001, kernel=linear;, score=-0.066 total time=  22.2s\n",
      "[CV 2/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.820 total time=  28.9s\n",
      "[CV 3/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.827 total time=  25.9s\n",
      "[CV 4/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.341 total time=  23.2s\n",
      "[CV 5/5] END ..C=2, gamma=0.0001, kernel=linear;, score=0.785 total time=  26.2s\n",
      "[CV 1/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.600 total time=  39.0s\n",
      "[CV 2/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.491 total time=  38.5s\n",
      "[CV 3/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.480 total time=  38.2s\n",
      "[CV 4/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.544 total time=  36.7s\n",
      "[CV 5/5] END .C=2, gamma=0.0001, kernel=sigmoid;, score=0.545 total time=  40.0s\n",
      "[CV 1/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.106 total time=  56.0s\n",
      "[CV 2/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.166 total time=  58.5s\n",
      "[CV 3/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.055 total time=  51.9s\n",
      "[CV 4/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.063 total time=  59.2s\n",
      "[CV 5/5] END ...C=2, gamma=0.0001, kernel=poly;, score=-0.030 total time=  54.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.320 total time=  31.7s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.764 total time=  35.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.742 total time=  33.4s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.768 total time=  34.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.792 total time=  34.1s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=linear;, score=-0.068 total time=  18.8s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.820 total time=  21.4s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.826 total time=  23.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.513 total time=  20.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.786 total time=  19.4s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.478 total time=  28.1s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.718 total time=  27.9s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.690 total time=  26.9s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.731 total time=  27.3s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.757 total time=  29.3s\n",
      "[CV 1/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.082 total time=  54.9s\n",
      "[CV 2/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.150 total time=  56.1s\n",
      "[CV 3/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.040 total time=  52.9s\n",
      "[CV 4/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.047 total time=  57.7s\n",
      "[CV 5/5] END ....C=1, gamma=0.001, kernel=poly;, score=-0.010 total time=  55.3s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.599 total time=  53.5s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.491 total time=  50.8s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.480 total time=  50.4s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.544 total time=  50.6s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.545 total time=  51.9s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=linear;, score=-0.068 total time=  19.4s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.820 total time=  22.2s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.826 total time=  21.2s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.513 total time=  21.6s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.786 total time=  21.5s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.485 total time=  46.9s\n",
      "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.356 total time=  45.3s\n",
      "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.368 total time=  42.1s\n",
      "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.429 total time=  43.3s\n",
      "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.429 total time=  45.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.106 total time=  57.7s\n",
      "[CV 2/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.166 total time=  58.1s\n",
      "[CV 3/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.055 total time=  54.7s\n",
      "[CV 4/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.063 total time=  56.3s\n",
      "[CV 5/5] END ...C=1, gamma=0.0001, kernel=poly;, score=-0.030 total time=  59.5s\n",
      "[CV 1/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.479 total time=  37.7s\n",
      "[CV 2/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.718 total time=  40.7s\n",
      "[CV 3/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.690 total time=  38.1s\n",
      "[CV 4/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.731 total time=  41.3s\n",
      "[CV 5/5] END ....C=0.5, gamma=0.001, kernel=rbf;, score=0.757 total time=  38.3s\n",
      "[CV 1/5] END C=0.5, gamma=0.001, kernel=linear;, score=-0.068 total time=  18.8s\n",
      "[CV 2/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.821 total time=  22.8s\n",
      "[CV 3/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.826 total time=  19.7s\n",
      "[CV 4/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.664 total time=  17.7s\n",
      "[CV 5/5] END .C=0.5, gamma=0.001, kernel=linear;, score=0.789 total time=  20.6s\n",
      "[CV 1/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.614 total time=  35.1s\n",
      "[CV 2/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.647 total time=  33.4s\n",
      "[CV 3/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.619 total time=  31.5s\n",
      "[CV 4/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.669 total time=  33.8s\n",
      "[CV 5/5] END C=0.5, gamma=0.001, kernel=sigmoid;, score=0.687 total time=  32.8s\n",
      "[CV 1/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.093 total time=  57.8s\n",
      "[CV 2/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.160 total time=  56.9s\n",
      "[CV 3/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.046 total time=  58.6s\n",
      "[CV 4/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.056 total time=  57.2s\n",
      "[CV 5/5] END ..C=0.5, gamma=0.001, kernel=poly;, score=-0.019 total time=  58.2s\n",
      "[CV 1/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.485 total time=  58.3s\n",
      "[CV 2/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.356 total time=  55.9s\n",
      "[CV 3/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.368 total time=  59.2s\n",
      "[CV 4/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.429 total time=  53.8s\n",
      "[CV 5/5] END ...C=0.5, gamma=0.0001, kernel=rbf;, score=0.428 total time=  59.7s\n",
      "[CV 1/5] END C=0.5, gamma=0.0001, kernel=linear;, score=-0.068 total time=  17.4s\n",
      "[CV 2/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.821 total time=  21.9s\n",
      "[CV 3/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.826 total time=  21.3s\n",
      "[CV 4/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.664 total time=  18.7s\n",
      "[CV 5/5] END C=0.5, gamma=0.0001, kernel=linear;, score=0.789 total time=  18.2s\n",
      "[CV 1/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.364 total time=  48.4s\n",
      "[CV 2/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.244 total time=  47.5s\n",
      "[CV 3/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.274 total time=  47.4s\n",
      "[CV 4/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.325 total time=  49.0s\n",
      "[CV 5/5] END C=0.5, gamma=0.0001, kernel=sigmoid;, score=0.330 total time=  48.7s\n",
      "[CV 1/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.106 total time= 1.0min\n",
      "[CV 2/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.166 total time=  56.9s\n",
      "[CV 3/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.055 total time=  56.9s\n",
      "[CV 4/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.063 total time=  59.6s\n",
      "[CV 5/5] END .C=0.5, gamma=0.0001, kernel=poly;, score=-0.030 total time=  57.8s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.600 total time=  54.5s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.492 total time=  52.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.480 total time=  51.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.544 total time=  51.8s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.545 total time=  53.4s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=linear;, score=-0.049 total time=  15.2s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.822 total time=  17.3s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.821 total time=  16.8s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.803 total time=  16.3s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.793 total time=  16.2s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.485 total time=  44.1s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.356 total time=  40.2s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.368 total time=  42.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.429 total time=  42.2s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.428 total time=  40.8s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.001, kernel=poly;, score=-0.103 total time=  57.5s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.001, kernel=poly;, score=-0.165 total time=  53.6s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.001, kernel=poly;, score=-0.054 total time=  55.8s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.001, kernel=poly;, score=-0.061 total time=  55.7s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.001, kernel=poly;, score=-0.027 total time=  54.5s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.228 total time= 1.2min\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.120 total time= 1.1min\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.173 total time= 1.6min\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.206 total time= 1.7min\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.223 total time= 1.7min\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=-0.049 total time=  23.9s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.822 total time=  23.2s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.821 total time=  20.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.803 total time=  19.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.793 total time=  19.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.133 total time= 1.2min\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.034 total time= 1.1min\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.104 total time=  57.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.124 total time= 1.2min\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.152 total time= 1.3min\n",
      "[CV 1/5] END .C=0.1, gamma=0.0001, kernel=poly;, score=-0.106 total time=  33.7s\n",
      "[CV 2/5] END .C=0.1, gamma=0.0001, kernel=poly;, score=-0.166 total time=  33.1s\n",
      "[CV 3/5] END .C=0.1, gamma=0.0001, kernel=poly;, score=-0.055 total time=  30.5s\n",
      "[CV 4/5] END .C=0.1, gamma=0.0001, kernel=poly;, score=-0.063 total time=  30.5s\n",
      "[CV 5/5] END .C=0.1, gamma=0.0001, kernel=poly;, score=-0.030 total time=  30.5s\n",
      "[CV 1/5] END ...C=0.05, gamma=0.001, kernel=rbf;, score=0.485 total time=  31.5s\n",
      "[CV 2/5] END ...C=0.05, gamma=0.001, kernel=rbf;, score=0.356 total time=  31.5s\n",
      "[CV 3/5] END ...C=0.05, gamma=0.001, kernel=rbf;, score=0.368 total time=  30.8s\n",
      "[CV 4/5] END ...C=0.05, gamma=0.001, kernel=rbf;, score=0.429 total time=  31.8s\n",
      "[CV 5/5] END ...C=0.05, gamma=0.001, kernel=rbf;, score=0.428 total time=  31.4s\n",
      "[CV 1/5] END C=0.05, gamma=0.001, kernel=linear;, score=-0.035 total time=   8.7s\n",
      "[CV 2/5] END C=0.05, gamma=0.001, kernel=linear;, score=0.821 total time=  10.0s\n",
      "[CV 3/5] END C=0.05, gamma=0.001, kernel=linear;, score=0.816 total time=  10.0s\n",
      "[CV 4/5] END C=0.05, gamma=0.001, kernel=linear;, score=0.812 total time=  11.7s\n",
      "[CV 5/5] END C=0.05, gamma=0.001, kernel=linear;, score=0.795 total time=  10.8s\n",
      "[CV 1/5] END C=0.05, gamma=0.001, kernel=sigmoid;, score=0.364 total time=  29.3s\n",
      "[CV 2/5] END C=0.05, gamma=0.001, kernel=sigmoid;, score=0.244 total time=  28.7s\n",
      "[CV 3/5] END C=0.05, gamma=0.001, kernel=sigmoid;, score=0.274 total time=  25.1s\n",
      "[CV 4/5] END C=0.05, gamma=0.001, kernel=sigmoid;, score=0.325 total time=  30.6s\n",
      "[CV 5/5] END C=0.05, gamma=0.001, kernel=sigmoid;, score=0.329 total time=  34.9s\n",
      "[CV 1/5] END .C=0.05, gamma=0.001, kernel=poly;, score=-0.104 total time=  36.0s\n",
      "[CV 2/5] END .C=0.05, gamma=0.001, kernel=poly;, score=-0.167 total time=  32.0s\n",
      "[CV 3/5] END .C=0.05, gamma=0.001, kernel=poly;, score=-0.054 total time=  36.5s\n",
      "[CV 4/5] END .C=0.05, gamma=0.001, kernel=poly;, score=-0.062 total time=  32.2s\n",
      "[CV 5/5] END .C=0.05, gamma=0.001, kernel=poly;, score=-0.028 total time=  35.3s\n",
      "[CV 1/5] END ..C=0.05, gamma=0.0001, kernel=rbf;, score=0.133 total time=  42.2s\n",
      "[CV 2/5] END ..C=0.05, gamma=0.0001, kernel=rbf;, score=0.034 total time=  41.7s\n",
      "[CV 3/5] END ..C=0.05, gamma=0.0001, kernel=rbf;, score=0.104 total time=  41.0s\n",
      "[CV 4/5] END ..C=0.05, gamma=0.0001, kernel=rbf;, score=0.124 total time=  46.4s\n",
      "[CV 5/5] END ..C=0.05, gamma=0.0001, kernel=rbf;, score=0.152 total time=  42.3s\n",
      "[CV 1/5] END C=0.05, gamma=0.0001, kernel=linear;, score=-0.035 total time=   7.9s\n",
      "[CV 2/5] END C=0.05, gamma=0.0001, kernel=linear;, score=0.821 total time=  10.1s\n",
      "[CV 3/5] END C=0.05, gamma=0.0001, kernel=linear;, score=0.816 total time=   9.4s\n",
      "[CV 4/5] END C=0.05, gamma=0.0001, kernel=linear;, score=0.812 total time=   9.3s\n",
      "[CV 5/5] END C=0.05, gamma=0.0001, kernel=linear;, score=0.795 total time=   9.6s\n",
      "[CV 1/5] END C=0.05, gamma=0.0001, kernel=sigmoid;, score=0.049 total time=  35.0s\n",
      "[CV 2/5] END C=0.05, gamma=0.0001, kernel=sigmoid;, score=-0.039 total time=  34.5s\n",
      "[CV 3/5] END C=0.05, gamma=0.0001, kernel=sigmoid;, score=0.046 total time=  34.1s\n",
      "[CV 4/5] END C=0.05, gamma=0.0001, kernel=sigmoid;, score=0.056 total time=  39.2s\n",
      "[CV 5/5] END C=0.05, gamma=0.0001, kernel=sigmoid;, score=0.088 total time=  36.1s\n",
      "[CV 1/5] END C=0.05, gamma=0.0001, kernel=poly;, score=-0.106 total time=  31.3s\n",
      "[CV 2/5] END C=0.05, gamma=0.0001, kernel=poly;, score=-0.166 total time=  33.6s\n",
      "[CV 3/5] END C=0.05, gamma=0.0001, kernel=poly;, score=-0.055 total time=  30.6s\n",
      "[CV 4/5] END C=0.05, gamma=0.0001, kernel=poly;, score=-0.063 total time=  31.3s\n",
      "[CV 5/5] END C=0.05, gamma=0.0001, kernel=poly;, score=-0.030 total time=  31.0s\n",
      "[CV 1/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.228 total time=  39.5s\n",
      "[CV 2/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.120 total time=  38.2s\n",
      "[CV 3/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.173 total time=  37.8s\n",
      "[CV 4/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.206 total time=  38.6s\n",
      "[CV 5/5] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.223 total time=  38.8s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.055 total time=   7.9s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.806 total time=  10.4s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.794 total time=  12.7s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.802 total time=  11.2s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=linear;, score=0.800 total time=   9.8s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.133 total time=  37.8s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.034 total time=  38.7s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.104 total time=  40.5s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.124 total time=  32.6s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=0.152 total time=  34.2s\n",
      "[CV 1/5] END .C=0.01, gamma=0.001, kernel=poly;, score=-0.106 total time=  33.7s\n",
      "[CV 2/5] END .C=0.01, gamma=0.001, kernel=poly;, score=-0.166 total time=  32.0s\n",
      "[CV 3/5] END .C=0.01, gamma=0.001, kernel=poly;, score=-0.055 total time=  31.5s\n",
      "[CV 4/5] END .C=0.01, gamma=0.001, kernel=poly;, score=-0.063 total time=  33.4s\n",
      "[CV 5/5] END .C=0.01, gamma=0.001, kernel=poly;, score=-0.029 total time=  32.0s\n",
      "[CV 1/5] END .C=0.01, gamma=0.0001, kernel=rbf;, score=-0.031 total time=  49.7s\n",
      "[CV 2/5] END .C=0.01, gamma=0.0001, kernel=rbf;, score=-0.105 total time=  50.7s\n",
      "[CV 3/5] END .C=0.01, gamma=0.0001, kernel=rbf;, score=-0.008 total time=  55.1s\n",
      "[CV 4/5] END .C=0.01, gamma=0.0001, kernel=rbf;, score=-0.008 total time=  56.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.027 total time=  56.6s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.055 total time=   9.2s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.806 total time=  12.3s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.794 total time=  11.8s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.802 total time=  11.5s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=linear;, score=0.800 total time=  11.3s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=-0.067 total time=  43.8s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=-0.133 total time=  39.4s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=-0.030 total time=  39.9s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=-0.036 total time=  40.8s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=0.001 total time=  39.4s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=poly;, score=-0.106 total time=  32.4s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=poly;, score=-0.166 total time=  32.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=poly;, score=-0.055 total time=  31.2s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=poly;, score=-0.063 total time=  32.4s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=poly;, score=-0.030 total time=151.0min\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "'''Thử với SVR: lấy y_state và u để tìm'''\n",
    "param_grid = {'C': [10, 5, 2, 1, 0.5, 0.1, 0.05, 0.01],  \n",
    "              'gamma': [ 0.001, 0.0001], \n",
    "              'kernel': ['rbf','linear','sigmoid','poly']\n",
    "               }  \n",
    "X_svr = state\n",
    "y_svr = control\n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3, error_score='raise')   \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_svr, y_svr) \n",
    "print(grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
